# -*- coding: utf-8 -*-
"""CIFAR10_cnn_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13XKPzuZdBsNNaHQg18FPIEsXPFm5aAjK
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import tensorflow as tf
from tensorflow.keras import layers
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense, Dropout, MaxPooling2D, Conv2D
from sklearn.metrics import confusion_matrix
import seaborn as sns

np.random.seed(0)

"""# **Getting Data from the Files**"""

from tensorflow.keras.datasets import cifar10
(x_train , y_train) , (x_test, y_test) = cifar10.load_data()
print(f"Shape of x_train : {x_train.shape}")
print(f"Shape of y_train : {y_train.shape}")
print(x_test.shape)
print(y_test.shape)

x_train = x_train / 255.0
x_test = x_test / 255.0
from tensorflow.keras.utils import to_categorical
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

num_classes = 10
f, ax= plt.subplots(1, 10, figsize=(20, 20))
y_train_labels = np.argmax(y_train, axis=1)
for i in range(10):
  ax[i].imshow(x_train[i])
  ax[i].set_title("Label: {}".format(i), fontsize=16)
  ax[i].axis('off')
print(np.unique(y_train_labels))
print(np.bincount(y_train_labels))
plt.show()

# # This one visualizes rotation of image . Why? because i wanted to find out should the
# # model have aggressive data augmentation for rotation.
# sample = x_train[0]


# fig, axes = plt.subplots(1, 4, figsize=(12, 3))

# axes[0].imshow(sample)
# axes[0].set_title('Original')


# from scipy import ndimage
# axes[1].imshow(ndimage.rotate(sample, 18, reshape=False))=
# axes[1].set_title('18° (0.05)')

# axes[2].imshow(ndimage.rotate(sample, 36, reshape=False))
# axes[2].set_title('36° (0.1)')

# axes[3].imshow(ndimage.rotate(sample, 72, reshape=False))
# axes[3].set_title('72° (0.2) - ah hell nah')

# plt.show()

"""## **Preparing of Data. Augmentation and setting up the model.**

"""

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.05),
    layers.RandomZoom(0.1)
])

rescale = tf.keras.Sequential([
    layers.Rescaling(1./255)
])

modelCNN = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(32,32,3)),
    data_augmentation,
    Conv2D(32, (3,3), activation='relu', padding='same'),
    Conv2D(64, (3,3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    MaxPooling2D((2,2)),
    Dropout(0.3),
    Conv2D(128, (3,3), activation='relu', padding='same'),
    Conv2D(256, (3,3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    MaxPooling2D((2,2)),
    Dropout(0.3),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])

optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)

modelCNN.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
modelCNN.summary()

"""## **Training time**"""

batch_size = 64
epochs = 50

historyCNN = modelCNN.fit(x=x_train, y=y_train , batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))

print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))
print(tf.config.list_physical_devices('GPU'))
# Just to check if my run time type is on the actual GPU i set.

"""### **Evaluation of Training Accuracy and Validation Accuracy**

"""

print(f"Train Accuracy {historyCNN.history['accuracy'][-1:]}")
print(f"Valid Accuracy {historyCNN.history['val_accuracy'][-1:]}")
print(f"Train Loss {historyCNN.history['loss'][-1:]}")
print(f"Valid Loss {historyCNN.history['val_loss'][-1:]}")
train_acc = historyCNN.history['accuracy'][-1]
val_acc = historyCNN.history['val_accuracy'][-1]

gap = train_acc - val_acc
gap_percent = 100 * gap

print(f"Accuracy Gap: {gap_percent:.2f} percentage points")
plt.plot(historyCNN.history['accuracy'], label='train_accuracy')
plt.plot(historyCNN.history['val_accuracy'], label='validation_accuracy')
plt.legend()
plt.show()
plt.plot(historyCNN.history['loss'], label='train_loss')
plt.plot(historyCNN.history['val_loss'], label='validation_loss')
plt.legend()
plt.show()
test_loss, test_acc = modelCNN.evaluate(x_test, y_test)
print("Test Loss: {}, Test Accuracy: {}".format(test_loss, test_acc))

y_pred = modelCNN.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
print(y_pred)
print(y_pred_classes)

# single example
random_idx = np.random.choice(len(x_test))
x_sample = x_test[random_idx]
y_true = np.argmax(y_test, axis=1)
y_sample_true = y_true[random_idx]
y_sample_pred_class = y_pred_classes[random_idx]

plt.title("Predicted: {}, True; {}".format(y_sample_pred_class, y_sample_true), fontsize=16)
plt.imshow(x_sample)
if y_sample_pred_class != y_sample_true:
  print("Incorrect Prediction!")
else:
  print("Correct Prediction! hooray")
confusion_mtx = confusion_matrix(y_true, y_pred_classes)

# plot
fig, ax = plt.subplots(figsize=(15,10))
ax = sns.heatmap(confusion_mtx, annot=True, fmt='d', ax=ax, cmap="Blues")
ax.set_xlabel('Predicted Label')
ax.set_ylabel('True Label')
ax.set_title('Confusion Matrix');

