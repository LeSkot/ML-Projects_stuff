# -*- coding: utf-8 -*-
"""FashionMNIST_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qhbOkHHQIHV6SoEl9S81VSRm69o9fpAf
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import tensorflow as tf
from tensorflow.keras import layers
from keras.models import Sequential
from keras.layers import Dropout, Flatten, Dense, Dropout, MaxPooling2D, Conv2D
from sklearn.metrics import confusion_matrix
import seaborn as sns

np.random.seed(0)

"""# **#Data**

"""

from keras.datasets import fashion_mnist
(x_train, y_train) , (x_test , y_test) = tf.keras.datasets.fashion_mnist.load_data()

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)

"""# **# Visualize Examples of MNIST**"""

num_classes = 10
f, ax= plt.subplots(1, num_classes, figsize=(20, 20))

for i in range(0, num_classes):
  sample = x_train[y_train == i][0]
  ax[i].imshow(sample, cmap='gray')
  ax[i].set_title("Label: {}".format(i), fontsize=16)

for i in range(10):
  print(y_train[i])

x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

x_train = np.expand_dims(x_train, axis=-1)
x_test = np.expand_dims(x_test, axis=-1)

y_train = tf.keras.utils.to_categorical(y_train, num_classes)
y_test = tf.keras.utils.to_categorical(y_test, num_classes)
print(x_train.shape)
print(x_test.shape)

for i in range(10):
  print(y_train[i])

"""# **Prepare of Data**

# **MLP vs CNN . Plus added regularization**
"""

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.1)
])

rescale_grayscale = tf.keras.Sequential([
    layers.Rescaling(1./255)
])

modelMLP = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(28, 28, 1)),
    data_augmentation,
    rescale_grayscale,
    tf.keras.layers.Flatten(),
    Dense(units=256, activation='relu'),
    Dense(units=128, activation='relu'),
    Dense(units=64, activation='relu'),
    Dense(units=64, activation='relu'),
    Dropout(0.2),
    Dense(units=10, activation='softmax' )
])

modelMLP.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
modelMLP.summary()
# For the MLP I found out that 'data_augm...' and the rescale are making the MLP Model to Underfit
# Since the FashionMNIST data training set does not feature random rotation.
modelCNN = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(28,28,1)),
    layers.Rescaling(1./255),
    Conv2D(32, (3,3), activation='relu', padding='same'),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu', padding='same'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(10, activation='softmax')
])

new_learning_rate = 0.001

optimizer = tf.keras.optimizers.Adam(learning_rate=new_learning_rate)

modelCNN.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
modelCNN.summary()

"""# **Train!**"""

batch_size = 512
epochs=15
# I wanted to see the difference between the MLP model and the CNN model
# Especially for image recognition
# historyMLP = modelMLP.fit(x=x_train, y=y_train , batch_size=batch_size, epochs=epochs)

batch_size = 64
epochs=30
history = modelCNN.fit(x=x_train, y=y_train , batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))

"""# **To Evaluate.**"""

print(history.history['accuracy'])
print(history.history['val_accuracy'])

plt.plot(history.history['accuracy'], label='train')
plt.plot(history.history['val_accuracy'], label='validation')
plt.legend()
plt.show()
test_loss, test_acc = modelCNN.evaluate(x_test, y_test)
print("Test Loss: {}, Test Accuracy: {}".format(test_loss, test_acc))

y_pred = modelCNN.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
print(y_pred)
print(y_pred_classes)

# Single Example
random_idx = np.random.choice(len(x_test))
x_sample = x_test[random_idx]
y_true = np.argmax(y_test, axis=1)
y_sample_true = y_true[random_idx]
y_sample_pred_class = y_pred_classes[random_idx]

plt.title("Predicted: {}, True; {}".format(y_sample_pred_class, y_sample_true), fontsize=16)
plt.imshow(x_sample.reshape(28, 28), cmap='gray')

"""# **Confusion Matrix**"""

confusion_mtx = confusion_matrix(y_true, y_pred_classes)

# Plot
fig, ax = plt.subplots(figsize=(15,10))
ax = sns.heatmap(confusion_mtx, annot=True, fmt='d', ax=ax, cmap="Blues")
ax.set_xlabel('Predicted Label')
ax.set_ylabel('True Label')
ax.set_title('Confusion Matrix');

"""# **To Investigate some errors**

"""

errors = (y_pred_classes - y_true != 0)
y_pred_classes_errors = y_pred_classes[errors]
y_pred_errors = y_pred[errors]
y_true_errors = y_true[errors]
x_test_errors = x_test[errors]

y_pred_errors_probability = np.max(y_pred_errors, axis=1)
true_probability_errors = np.diagonal(np.take(y_pred_errors, y_true_errors, axis=1))
diff_errors_pred_true = y_pred_errors_probability - true_probability_errors
# Gets list of indices of sorted differences
sorted_idx_diff_errors = np.argsort(diff_errors_pred_true)
top_idx_diff_errors = sorted_idx_diff_errors[-5:] # Last 5 Ones

# This shows the top errors
num = len(top_idx_diff_errors)
f, ax = plt.subplots(1, num, figsize=(30,30))

for i in range(0, num):
  idx = top_idx_diff_errors[i]
  sample = x_test_errors[idx].reshape(28,28)
  y_t = y_true_errors[idx]
  y_p = y_pred_classes_errors[idx]
  ax[i].imshow(sample, cmap='gray')
  ax[i].set_title("Predicted Label: {}\nTrue Label: {}".format(y_p, y_t), fontsize=22)

